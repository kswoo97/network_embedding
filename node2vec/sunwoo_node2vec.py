import numpy as np
import time

class node2vec :

    def __init__(self, data):
        self.data = data
        self.node_num = data.shape[0]
        self.one_dist = data
        self.two_dist = data.dot(data)
        for i in range(self.two_dist.shape[0]) : self.two_dist[i,i] = 0


        # calculating the distance per each

    def random_prob(self, out_index) :

        prob = np.around(np.delete(np.sum(self.data, 0)**0.75, out_index)/np.sum(np.delete(np.sum(self.data, 0)**0.75, out_index)), 3)
        if np.sum(prob) == 1 :
            return prob
        elif  np.sum(prob) > 1 :
            prob[0] = prob[0] - (np.sum(prob) - 1)
            return prob
        else :
            prob[0] = prob[0] + (1 - np.sum(prob))
            return prob

    def initialize (self, k, init_method, var) :

        if init_method == 'normal' :
            self.h = np.random.normal(0, var, self.node_num*k).reshape(self.node_num, k)
        elif init_method == 'uniform' :
            self.h = np.random.uniform(-var, var, self.node_num*k).reshape(self.node_num, k)
        else :
            raise TypeError('Got unexpected method. Either normal or uniform should be given')

    def bias_random_walk (self, p, q, epochs, walk_length) :
        norm_con = 1/q + 1 + 1/p
        out_p, same_p, in_p = 1/(p*norm_con), 1/norm_con, 1/(q*norm_con)
        index = np.arange(self.data.shape[0])
        total_walk = []
        total_decision = []
        for epoch in range(epochs) :
            np.random.shuffle(index)
            for i in index : # Starting node is picked / Remember it has to remember where it comes from
                partial_walk = [i]
                partial_decision = []
                for k in range(walk_length - 1) :
                    way = np.random.choice([0, 1, 2], 1, p = [out_p, same_p, in_p])[0]
                    if k == 0 : # There is no previous step / So it have to go further
                        next_node = np.random.choice(np.where(self.data[i] > 0)[0], 1)[0]
                        partial_walk.append(next_node)
                        cur_pos = next_node
                        prev_pos = i
                    else :
                        if way == 0 : # Going Back
                            partial_walk.append(prev_pos)
                            prev_pos = cur_pos
                            cur_pos = partial_walk[-1]
                        elif way == 1 : # To the same distance
                            # If exists, then go there
                            # If it does not exist, then return back
                            might_be,part = np.where(self.data[cur_pos] > 0)[0], np.where(self.data[prev_pos] > 0)[0]
                            next_index = np.isin(might_be, part)
                            if np.sum(next_index) > 0 : # To the Same Distance
                                partial_walk.append(np.random.choice(might_be[next_index], 1)[0])
                                prev_pos = cur_pos
                                cur_pos = partial_walk[-1]
                            else :  # O.W.Getting Back
                                partial_walk.append(prev_pos)
                                prev_pos = cur_pos
                                cur_pos = partial_walk[-1]
                        else : # To the Further away!
                            might_be, part = np.where(self.data[cur_pos] > 0)[0], np.where(self.two_dist[prev_pos] > 0)[0]
                            next_index = np.isin(might_be, part)
                            if np.sum(next_index) > 0 :
                                partial_walk.append(np.random.choice(might_be[next_index], 1)[0])
                                prev_pos = cur_pos
                                cur_pos = partial_walk[-1]
                            else:  # O.W.Getting Back
                                partial_walk.append(prev_pos)
                                prev_pos = cur_pos
                                cur_pos = partial_walk[-1]
                    partial_decision.append(way)
                total_walk.append(partial_walk)
                total_decision.append(partial_decision)
        self.total_walk, self.total_decision = total_walk, total_decision

    def sequence_neighbor_extractor(self, sequence1, window_size, target_position) :

        """
        :param sequence1: Sequence Generated by
        :param window_size: as it is written
        :param target_position: index that would be a target
        :return: required index for the model
        """

        input_index = sequence1[target_position]
        target_index = []

        if target_position < window_size :
            target_index = sequence1[:target_position] + sequence1[target_position + 1 : target_position + window_size + 1]

        elif len(sequence1[target_position + 1 : ]) < window_size:
            target_index = sequence1[target_position - window_size : target_position] + sequence1[target_position + 1 : ]

        else :
            target_index = sequence1[target_position - window_size : target_position] + sequence1[target_position + 1 : target_position + window_size + 1]

        return input_index, target_index

    def sigmoid(self, x):

        return 1/(1+np.exp(-x))

    def fit (self, k, init_method, var,
             p, q, epochs, walk_length, window_size, lr,
             neg_sample) :
        """
        Main Training Loop
        1. 전체 walk를 모두 생성해서 list에 할당합니다.
        2. 하나씩 walk를 꺼내서 학습에 사용합니다.
        :param k: embedding size
        :param init_method: Initializing method
        :param var: Variance or Bound for Normal or Uniform
        :param p: return parameter
        :param q: in-out parameter
        :param epochs: training epochs
        :param walk_length: R.W. Length
        :param window_size: Determine the neighbors
        :param lr: Learning Rate
        :param neg_sample : number of negative samples
        :return: None. Just Training Procedure and trained embedding vectors
        """
        self.initialize(k, init_method, var)
        self.bias_random_walk(p, q, epochs, walk_length)
        total_loss = []
        print('Training Started!')
        start_time = time.time()
        for epoch_, walk in enumerate(self.total_walk) : # Each walk is extracted
            if epoch_ % self.data.shape[0] == 0 :
                part_loss = []
            for i in range(walk_length) :
                ni, nj_all = self.sequence_neighbor_extractor(walk, window_size, i)
                for nj in nj_all : # Pairwise Updating
                    neg_k = np.random.choice(np.delete(np.arange(34), ni), neg_sample, p = self.random_prob(ni)) # Generate Negative Samples
                    ui = self.h[ni]
                    uj = self.h[nj]
                    u_neg = self.h[neg_k]

                    O1 = -np.log(self.sigmoid(np.sum(ui*uj))) - np.sum(np.log(self.sigmoid(np.sum(-u_neg*ui, 1))))
                    dE_dui = (self.sigmoid(np.sum(ui*uj)) - 1)*uj + np.sum((self.sigmoid(np.sum(u_neg*ui, 1)).reshape(-1,1)*u_neg), 0)
                    dE_duj = (self.sigmoid(np.sum(ui*uj)) - 1)*ui
                    dE_dneg = self.sigmoid(np.sum(u_neg*ui, 1).reshape(-1,1)).dot(ui.reshape(1,-1))

                    self.h[ni] = ui - lr * dE_dui
                    self.h[nj] = uj - lr * dE_duj
                    self.h[neg_k] = u_neg - lr * dE_dneg
                    part_loss.append(O1)

            if epoch_ % self.data.shape[0] == 0 :
                total_loss.append(np.mean(part_loss))

        print('Learning Finshed in {} seconds'.format(time.time() - start_time))
        self.loss = total_loss